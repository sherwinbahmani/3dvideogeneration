# @package _group_
name: stylenerf_mead

G_kwargs:
    class_name: "training.networks.Generator"
    z_dim: 512
    w_dim: 512

    mapping_kwargs:
        num_layers: ${spec.map}

    synthesis_kwargs:
        # global settings
        num_fp16_res: ${num_fp16_res}
        channel_base: 1
        channel_max: 1024
        conv_clamp: 256
        kernel_size: 1
        architecture: skip
        upsample_mode: "pixelshuffle"

        z_dim_bg: 32
        z_dim: 0
        z_dim_static: 0
        resolution_vol: 32
        resolution_start: 256 # 32
        rgb_out_dim: 64 # 64

        use_noise: False
        module_name: "training.stylenerf.NeRFSynthesisNetwork"
        no_bbox: True
        margin: 0
        magnitude_ema_beta: 0.999

        camera_kwargs:
            range_v: [1.4157963267948965, 1.7257963267948966]
            range_u: [-0.3, 0.3]
            range_radius: [1.0, 1.0]
            depth_range: [0.88, 1.12]
            fov: 12
            gaussian_camera: True
            angular_camera: True
            depth_transform:  ~
            dists_normalized: False
            ray_align_corner: False
            bg_start: 0.5
        
        renderer_kwargs:
            n_bg_samples: 4
            n_ray_samples: 14
            abs_sigma: False
            hierarchical: True
            no_background: False
            
        foreground_kwargs:
            positional_encoding: "normal"
            downscale_p_by: 1
            use_style: "StyleGAN2"
            predict_rgb: True
            use_viewdirs: False
            hidden_size: 128
            z_dim_motion: 512
            use_time: False # Use time as an input in NeRF along position
            encode_time: False # Positional encoding for time
            motion_gen: "embed" # ["none", "pre", "embed", "embed_concat"] Use motion generator with latent code
            encode_time_embed: False
            norm_time: False
            use_content: False
            motion_hidden_size: 128
            motion_hidden_blocks: 1
            dynamic_blending: null #"learn" # null, "learn", "equal"
        
        foreground_static_kwargs: null

        background_kwargs:
            positional_encoding: "normal"
            hidden_size: 64
            z_dim_motion: null
            n_blocks: 4
            downscale_p_by: 1
            skips: []
            inverse_sphere: True
            use_style: "StyleGAN2"
            predict_rgb: True
            use_viewdirs: False
            use_time: False # Use time as an input in NeRF along position
            encode_time: False # Positional encoding for time
            motion_gen: "none" # ["none", "pre", "embed"] Use motion genaerator with latent code
            use_content: False
            encode_time_embed: False
            norm_time: False

        upsampler_kwargs:
            channel_base: ${model.G_kwargs.synthesis_kwargs.channel_base}
            channel_max:  ${model.G_kwargs.synthesis_kwargs.channel_max}
            no_2d_renderer: False
            no_residual_img: False
            block_reses: ~
            shared_rgb_style: False
            upsample_type: "bilinear"
        
        progressive: False

        # reuglarization
        n_reg_samples: 16
        reg_full: True

        # Bg loss
        bg_loss_type: null # null, "both", "img", "feat"

D_kwargs:
    class_name: "training.stylenerf.OurDiscriminator"
    epilogue_kwargs:
        mbstd_group_size: ${spec.mbstd}

    num_fp16_res: ${num_fp16_res}
    channel_base: ${spec.fmaps}
    channel_max: 512
    conv_clamp: 256
    architecture: skip
    progressive: ${model.G_kwargs.synthesis_kwargs.progressive}
    lowres_head: ${model.G_kwargs.synthesis_kwargs.resolution_start}
    upsample_type: "bilinear"
    resize_real_early: True

# loss kwargs
loss_kwargs:
    pl_batch_shrink: 2
    pl_decay: 0.01
    pl_weight: 2
    style_mixing_prob: 0.9
    curriculum: [24000, 25000] #[500, 2000] #[500,5000]
    img_disc_weight: 1.0
    other_weights:
        bg_loss: 1.0 #null